* case1 ~ case4 의 경우에 각각 25장씩 4 * 4해서 400장의 검증 데이터셋을 구성했다.
  앞으로의 테스트는 이 데이터를 이용해서 진행할 예정이다.

* 아래의 조건으로 데이터의 비율별 검증도 테스트를 진행했다.
 1) 10배의 데이터 확장
 2) train : val = 7 : 3
 3) 배치사이즈 : 8
 4) 에폭 : 8

* 무작위비율의 validation loss : 0.14
* 일정한비율의 validation loss : 0.18
 
* 모두 약 1800장의 데이터로 학습을 진행하였는데
  value loss는 무작위 비율이 더 안좋게 나왔지만 커스텀 검증 데이터셋으로 테스트 해 본 결과
  일정한 비율의 데이터셋의 학습모델이 조금 더 편향되지 않은 이상적인 결과를 도출했다.

* 이전 4에폭 4배치 모델의 경우 에폭수가 너무 적었고 일정비율 데이터의 학습모델이
  value loss가 0.28라는 큰 수치가 나왔기 때문에 수치가 안좋았는데 이번엔 비슷한 value loss에서
  커스텀 데이터셋 비교 결과 일정한 비율의 데이터셋이 조금 더 우수한 결과를 보였다.

* 따라서 앞으로는 일정한 비율(1:1:1:1)의 데이터셋을 기준으로 학습의 최적화를 진행할 예정이다.
  (오버피팅을 방지하기 위해서 이기도 함)